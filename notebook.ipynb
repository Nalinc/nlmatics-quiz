{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "\n",
    "Given two sentences that are known to be paraphrases, pick the phrases that are similar and\n",
    "contribute to their overall similarity\n",
    "\n",
    "# Example:\n",
    "\n",
    "Sentence 1: Charlie Chan is off the case for the Fox Movie Channel.  <br/>\n",
    "Sentence 2: The Fox Movie Channel has banned Charlie Chan\n",
    "\n",
    "Output: <br/>\n",
    "\n",
    "Banned, off the case <br/>\n",
    "Charlie Chan, Charlie Chan <br/>\n",
    "Fox Movie Channel, Fox Movie Channel<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from bert_serving.client import BertClient\n",
    "import spacy\n",
    "import textacy\n",
    "from spacy import displacy\n",
    "import en_core_web_sm\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Language Models\n",
    "\n",
    "Spacy provides downloadable pretrained language models for important natural language tasks such as tagging, parsing and entity recognition. \n",
    "\n",
    "A comphrensive list of available models can be seen at https://spacy.io/models/en. \n",
    "\n",
    "For the sake of this task, we are using **en_core_web_sm**. The following code expects this module is already available. If not, it can be downloaded by running\n",
    "```\n",
    "python -m spacy download en_core_web_sm\n",
    "```\n",
    "\n",
    "Models can be loaded using spaCy's build-in loader, or as a normal python module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load('en_core_web_sm')\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load sentences that are knwon to be paraphrases using the language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_1 = nlp(\"Feelings about current business conditions improved substantially from the first quarter, jumping from 40 to 55.\")\n",
    "sentence_2 = nlp(\"Assessment of current business conditions improved substantially, the Conference Board said, jumping to 55 from 40 in the first quarter.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible techniques to solve the problem\n",
    "\n",
    "The task can be solved by decomposing the input sentences into individual phrases and comparing similarity of the obtained phrases in their vector representation.\n",
    "\n",
    "## Obtaining phrases\n",
    "\n",
    "- **Method 1: Chunking**\n",
    "\n",
    "    Text chunking, also referred to as shallow parsing, is a task that follows Part-Of-Speech Tagging and that adds more structure to the sentence. The result is a grouping of the words in “chunks”. We use this technique for noun phrase extraction.\n",
    "    \n",
    "- **Method 2: Parsing**\n",
    "    Parsing in NLP is the process of determining the syntactic structure of a text by analyzing its constituent words based on an underlying grammar (of the language). Parsing results in a tree and can be of following two types\n",
    "    - Constituent parsing\n",
    "    - Dependency parsing\n",
    "\n",
    "## Calculating similarity\n",
    "Similarity between phrases can be calculated usign any distance metric technique (like Jaccard similarity, or Cosine scores). For this, the two phrases being compared needs to be converted into their respective vector form. One of the popular ways to convert words into numeric vectors is using distributed representation of words. However, context-free models such as word2vec or GloVe generate a single word embedding representation for each word in the vocabulary and do not capture polysemy. Contextual models like BERT and ELMo generate a representation of each word that is based on the other words in the sentence. \n",
    "\n",
    "\n",
    "### Current Approach\n",
    "\n",
    "For the sake of this assignment, we have used **Method 1** mentioned above to extract the noun-phrases from input sentence pairs. This is achieved using spaCy. For similarity comparison, we use pre-trained BERT embeddings that run through bert-as-a-service (https://github.com/hanxiao/bert-as-service). Cosine similarity is obtained by simply calculating the dot product of the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function extracts the noun phrases from a given input sentence and returns a list\n",
    "def extract_noun_phrases(doc):\n",
    "    phrases_extracted = []\n",
    "    for chunk in doc.noun_chunks:\n",
    "#         print(chunk.text, chunk.root.text, chunk.root.dep_, chunk.root.head.text)\n",
    "        phrases_extracted.append(chunk.text)\n",
    "    return phrases_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Feelings', 'current business conditions', 'the first quarter']"
      ]
     },
     "execution_count": 746,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_1_phrases = extract_noun_phrases(sentence_1)\n",
    "sentence_1_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Assessment',\n",
       " 'current business conditions',\n",
       " 'the Conference Board',\n",
       " 'the first quarter']"
      ]
     },
     "execution_count": 747,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_2_phrases = extract_noun_phrases(sentence_2)\n",
    "sentence_2_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following code assumes that a separate bert-serving-server is running at port 5555, that converts a string into BERT encoding\n",
    "\n",
    "```\n",
    "bert-serving-start -model_dir /Users/nalinc/Projects/word_embeddings/bert/uncased_L-12_H-768_A-12/ -num_worker=4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_phrases(sentence_1_phrases, sentence_2_phrases):\n",
    "    def calculate_similarity(pair):\n",
    "        query_vec_1, query_vec_2 = bert_client.encode(pair)\n",
    "        cosine = np.dot(query_vec_1, query_vec_2) / (np.linalg.norm(query_vec_1) * np.linalg.norm(query_vec_2))\n",
    "        return 1/(1 + math.exp(-100*(cosine - 0.95)))\n",
    "    \n",
    "    similar_phrases = []\n",
    "    # Open a new connection to BERT Server\n",
    "    with BertClient(port=5555, port_out=5556, check_version=False) as bert_client:\n",
    "        # Find which of the two list of phrases is longer. We should only compare phrases with respect to smaller sentence\n",
    "        longer_phrase_length = sentence_1_phrases if len(sentence_1_phrases) > len(sentence_2_phrases) else sentence_2_phrases\n",
    "        shorter_phrase_length = sentence_1_phrases if len(sentence_1_phrases) <= len(sentence_2_phrases) else sentence_2_phrases\n",
    "\n",
    "        for i in shorter_phrase_length:\n",
    "            most_similar_j_index, most_similar_j = 0,0\n",
    "            for index_j,j in enumerate(longer_phrase_length):\n",
    "                print(i,\"\\t\\t\\t\",j)\n",
    "                i_j_similarity = calculate_similarity([i,j])\n",
    "                if i_j_similarity >= most_similar_j:\n",
    "                    most_similar_j_index = index_j\n",
    "                    most_similar_j = i_j_similarity\n",
    "            print(most_similar_j)\n",
    "            similar_phrases.append([i, longer_phrase_length[most_similar_j_index]])\n",
    "    return similar_phrases\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feelings \t\t\t Assessment\n",
      "Feelings \t\t\t current business conditions\n",
      "Feelings \t\t\t the Conference Board\n",
      "Feelings \t\t\t the first quarter\n",
      "8.828242445860665e-07\n",
      "current business conditions \t\t\t Assessment\n",
      "current business conditions \t\t\t current business conditions\n",
      "current business conditions \t\t\t the Conference Board\n",
      "current business conditions \t\t\t the first quarter\n",
      "0.9933072283262605\n",
      "the first quarter \t\t\t Assessment\n",
      "the first quarter \t\t\t current business conditions\n",
      "the first quarter \t\t\t the Conference Board\n",
      "the first quarter \t\t\t the first quarter\n",
      "0.9933071490757153\n"
     ]
    }
   ],
   "source": [
    "similar_phrases = find_similar_phrases(sentence_1_phrases, sentence_2_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Feelings', 'Assessment'],\n",
       " ['current business conditions', 'current business conditions'],\n",
       " ['the first quarter', 'the first quarter']]"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simply output the phrases with maximum similarity score in above output\n",
    "similar_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output with other examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Fox Movie Channel \t\t\t Charlie Chan\n",
      "The Fox Movie Channel \t\t\t the case\n",
      "The Fox Movie Channel \t\t\t the Fox Movie Channel\n",
      "0.9933071490757153\n",
      "Charlie Chan \t\t\t Charlie Chan\n",
      "Charlie Chan \t\t\t the case\n",
      "Charlie Chan \t\t\t the Fox Movie Channel\n",
      "0.9933070698242378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['The Fox Movie Channel', 'the Fox Movie Channel'],\n",
       " ['Charlie Chan', 'Charlie Chan']]"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_1 = nlp(\"Charlie Chan is off the case for the Fox Movie Channel.\")\n",
    "sentence_2 = nlp(\"The Fox Movie Channel has banned Charlie Chan.\")\n",
    "\n",
    "sentence_1_phrases = extract_noun_phrases(sentence_1)\n",
    "sentence_2_phrases = extract_noun_phrases(sentence_2)\n",
    "\n",
    "similar_phrases = find_similar_phrases(sentence_1_phrases, sentence_2_phrases)\n",
    "similar_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative Way(s)\n",
    "\n",
    "Results can be improved and further fine-tuned by using various techniques as described below\n",
    "- Using other rule-based approaches to extract verb-phrases, adjective-phrases etc.\n",
    "- By training a deep neural network on various dependency-trees obtained from the pair of sentences. Through this, the problem can be decomposed to \n",
    "\n",
    "Essentially, if we can extract more relevant (as well as consistent) phrases from the input sentence pairs, then we can form more such similar pair of phrases. Following code illustrates a proof-of-concept for this kind of approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the dependency tree of input sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"f6055aeff7124bc3b7cc607644e0367d-0\" class=\"displacy\" width=\"1975\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Charlie</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Chan</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">off</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">case</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">Fox</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">Movie</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">Channel.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f6055aeff7124bc3b7cc607644e0367d-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,264.5 210.0,264.5 210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f6055aeff7124bc3b7cc607644e0367d-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f6055aeff7124bc3b7cc607644e0367d-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,264.5 385.0,264.5 385.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f6055aeff7124bc3b7cc607644e0367d-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f6055aeff7124bc3b7cc607644e0367d-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,264.5 560.0,264.5 560.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f6055aeff7124bc3b7cc607644e0367d-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M560.0,354.0 L568.0,342.0 552.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f6055aeff7124bc3b7cc607644e0367d-0-3\" stroke-width=\"2px\" d=\"M770,352.0 C770,264.5 910.0,264.5 910.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f6055aeff7124bc3b7cc607644e0367d-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,354.0 L762,342.0 778,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f6055aeff7124bc3b7cc607644e0367d-0-4\" stroke-width=\"2px\" d=\"M595,352.0 C595,177.0 915.0,177.0 915.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f6055aeff7124bc3b7cc607644e0367d-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M915.0,354.0 L923.0,342.0 907.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f6055aeff7124bc3b7cc607644e0367d-0-5\" stroke-width=\"2px\" d=\"M420,352.0 C420,2.0 1100.0,2.0 1100.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f6055aeff7124bc3b7cc607644e0367d-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1100.0,354.0 L1108.0,342.0 1092.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f6055aeff7124bc3b7cc607644e0367d-0-6\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,89.5 1795.0,89.5 1795.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f6055aeff7124bc3b7cc607644e0367d-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,354.0 L1287,342.0 1303,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f6055aeff7124bc3b7cc607644e0367d-0-7\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,264.5 1610.0,264.5 1610.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f6055aeff7124bc3b7cc607644e0367d-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,354.0 L1462,342.0 1478,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f6055aeff7124bc3b7cc607644e0367d-0-8\" stroke-width=\"2px\" d=\"M1645,352.0 C1645,264.5 1785.0,264.5 1785.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f6055aeff7124bc3b7cc607644e0367d-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,354.0 L1637,342.0 1653,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f6055aeff7124bc3b7cc607644e0367d-0-9\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,2.0 1800.0,2.0 1800.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f6055aeff7124bc3b7cc607644e0367d-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1800.0,354.0 L1808.0,342.0 1792.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"b91a8c6c4cb3434a8e47eb6ddb790a8e-0\" class=\"displacy\" width=\"1450\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Fox</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">Movie</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">Channel</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">has</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">banned</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">Charlie</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">Chan.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b91a8c6c4cb3434a8e47eb6ddb790a8e-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,2.0 575.0,2.0 575.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b91a8c6c4cb3434a8e47eb6ddb790a8e-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b91a8c6c4cb3434a8e47eb6ddb790a8e-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b91a8c6c4cb3434a8e47eb6ddb790a8e-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b91a8c6c4cb3434a8e47eb6ddb790a8e-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b91a8c6c4cb3434a8e47eb6ddb790a8e-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b91a8c6c4cb3434a8e47eb6ddb790a8e-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,89.5 920.0,89.5 920.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b91a8c6c4cb3434a8e47eb6ddb790a8e-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b91a8c6c4cb3434a8e47eb6ddb790a8e-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b91a8c6c4cb3434a8e47eb6ddb790a8e-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b91a8c6c4cb3434a8e47eb6ddb790a8e-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b91a8c6c4cb3434a8e47eb6ddb790a8e-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b91a8c6c4cb3434a8e47eb6ddb790a8e-0-6\" stroke-width=\"2px\" d=\"M945,264.5 C945,89.5 1270.0,89.5 1270.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b91a8c6c4cb3434a8e47eb6ddb790a8e-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270.0,266.5 L1278.0,254.5 1262.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(sentence_1, style=\"dep\")\n",
    "displacy.render(sentence_2, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_phrases(doc):\n",
    "    phrases_extracted = []\n",
    "    # print([token.text for token in doc[2].lefts])\n",
    "    root = [token for token in doc if token.head == token][0]\n",
    "    left_subtree_subjects = list(root.lefts)\n",
    "    right_subtree_subjects = list(root.rights)\n",
    "    subjects = left_subtree_subjects + right_subtree_subjects\n",
    "    \n",
    "    for subject in left_subtree_subjects:\n",
    "        _phrases = []\n",
    "        for descendant in subject.subtree:\n",
    "            if descendant.dep_ != \"punct\":\n",
    "                _phrases.append(descendant.text)\n",
    "            print(descendant.text, descendant.dep_, descendant.n_lefts, descendant.n_rights, [ancestor.text for ancestor in descendant.ancestors])\n",
    "        print(\"--\")\n",
    "        if len(_phrases):\n",
    "            phrases_extracted.append(\" \".join(_phrases))\n",
    "\n",
    "    phrases_extracted.append(\"\".join([root.text]))\n",
    "    \n",
    "    for subject in right_subtree_subjects:\n",
    "        _phrases = []\n",
    "        for descendant in subject.subtree:\n",
    "            if descendant.dep_ != \"punct\":\n",
    "                _phrases.append(descendant.text)\n",
    "            print(descendant.text, descendant.dep_, descendant.n_lefts, descendant.n_rights, [ancestor.text for ancestor in descendant.ancestors])\n",
    "        print(\"--\")\n",
    "        if len(_phrases):\n",
    "            phrases_extracted.append(\" \".join(_phrases))\n",
    "    \n",
    "    return phrases_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charlie compound 0 0 ['Chan', 'is']\n",
      "Chan nsubj 1 0 ['is']\n",
      "--\n",
      "off prep 0 1 ['is']\n",
      "the det 0 0 ['case', 'off', 'is']\n",
      "case pobj 1 0 ['off', 'is']\n",
      "--\n",
      "for prep 0 1 ['is']\n",
      "the det 0 0 ['Channel', 'for', 'is']\n",
      "Fox compound 0 0 ['Movie', 'Channel', 'for', 'is']\n",
      "Movie compound 1 0 ['Channel', 'for', 'is']\n",
      "Channel pobj 2 0 ['for', 'is']\n",
      "--\n",
      ". punct 0 0 ['is']\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "sentence_1_phrases = extract_phrases(sentence_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The det 0 0 ['Channel', 'banned']\n",
      "Fox compound 0 0 ['Channel', 'banned']\n",
      "Movie compound 0 0 ['Channel', 'banned']\n",
      "Channel nsubj 3 0 ['banned']\n",
      "--\n",
      "has aux 0 0 ['banned']\n",
      "--\n",
      "Charlie compound 0 0 ['Chan', 'banned']\n",
      "Chan dobj 1 0 ['banned']\n",
      "--\n",
      ". punct 0 0 ['banned']\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "sentence_2_phrases = extract_phrases(sentence_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charlie Chan \t\t\t The Fox Movie Channel\n",
      "Charlie Chan \t\t\t has\n",
      "Charlie Chan \t\t\t banned\n",
      "Charlie Chan \t\t\t Charlie Chan\n",
      "0.9933070698242378\n",
      "is \t\t\t The Fox Movie Channel\n",
      "is \t\t\t has\n",
      "is \t\t\t banned\n",
      "is \t\t\t Charlie Chan\n",
      "0.02589186437030154\n",
      "off the case \t\t\t The Fox Movie Channel\n",
      "off the case \t\t\t has\n",
      "off the case \t\t\t banned\n",
      "off the case \t\t\t Charlie Chan\n",
      "4.4969501981066854e-13\n",
      "for the Fox Movie Channel \t\t\t The Fox Movie Channel\n",
      "for the Fox Movie Channel \t\t\t has\n",
      "for the Fox Movie Channel \t\t\t banned\n",
      "for the Fox Movie Channel \t\t\t Charlie Chan\n",
      "0.003524340980437101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Charlie Chan', 'Charlie Chan'],\n",
       " ['is', 'has'],\n",
       " ['off the case', 'banned'],\n",
       " ['for the Fox Movie Channel', 'The Fox Movie Channel']]"
      ]
     },
     "execution_count": 757,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_phrases(sentence_1_phrases, sentence_2_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. https://spacy.io/usage/linguistic-features\n",
    "2. https://github.com/google-research/bert#pre-trained-models\n",
    "3. https://bert-as-service.readthedocs.io/en/latest/#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
